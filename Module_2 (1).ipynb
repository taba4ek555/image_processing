{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/stipot/image_processing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ik8hAMglofb9",
        "outputId": "84cfacd8-2dad-4b64-bfb0-c9473ec99b26"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'image_processing'...\n",
            "remote: Enumerating objects: 2321, done.\u001b[K\n",
            "remote: Counting objects: 100% (169/169), done.\u001b[K\n",
            "remote: Compressing objects: 100% (148/148), done.\u001b[K\n",
            "remote: Total 2321 (delta 23), reused 156 (delta 16), pack-reused 2152 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2321/2321), 125.24 MiB | 10.37 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n",
            "Updating files: 100% (2888/2888), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdAXU55RnJXh"
      },
      "source": [
        "# Модуль 2. Классификация изображений\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9miy_9mTnJXi"
      },
      "source": [
        "## Сопоставление изображений\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPCprDVRnJXi"
      },
      "source": [
        "### Алгоритмы сопоставления изображений\n",
        "\n",
        "Для реализации алгоритма классификации изображений, я предложу вам пример кода, использующий библиотеку tensorflow и keras. В этом примере мы будем использовать предварительно обученную модель MobileNetV2 для классификации изображений.\n",
        "\n",
        "Прежде всего, убедитесь, что у вас установлены tensorflow и keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKKzu7sdnJXi",
        "outputId": "dbd8c7b6-926f-4c07-b0e0-d7129a8f152c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "1: fur_coat (10.58%)\n",
            "2: bittern (2.80%)\n",
            "3: tiger (1.93%)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import (\n",
        "    preprocess_input,\n",
        "    decode_predictions,\n",
        ")\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Загрузка предварительно обученной модели MobileNetV2\n",
        "model = MobileNetV2(weights=\"imagenet\")\n",
        "\n",
        "\n",
        "def classify_image(img_path):\n",
        "    # Загрузка изображения, его предварительная обработка и расширение размерностей\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
        "    preprocessed_image = preprocess_input(img_array_expanded_dims)\n",
        "\n",
        "    # Прогнозирование и декодирование предсказаний\n",
        "    predictions = model.predict(preprocessed_image)\n",
        "    results = decode_predictions(predictions, top=3)[0]\n",
        "\n",
        "    # Вывод результатов\n",
        "    for i, (imagenet_id, label, score) in enumerate(results):\n",
        "        print(f\"{i + 1}: {label} ({score*100:.2f}%)\")\n",
        "\n",
        "\n",
        "# Пример использования\n",
        "img_path = \"texture_01.jpg\"\n",
        "classify_image(img_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trX3zJYinJXj"
      },
      "source": [
        "### Построение мозаики из изображений\n",
        "\n",
        "Для построения мозаики изображений на Python, можно использовать библиотеку PIL (Python Imaging Library), которая теперь доступна как Pillow. Ниже приведен пример кода, который создает мозаику из нескольких изображений. Допустим, у нас есть четыре изображения, и мы хотим их объединить в одно большое изображение-мозаику в формате 2x2.\n",
        "\n",
        "Прежде всего, убедитесь, что у вас установлена библиотека Pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "Y81oZ2NWnJXk",
        "outputId": "0e7f4317-42d6-41d1-ad61-d181494be048"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/result/mosaic.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-31123067b096>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Сохранение и показ мозаики\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mmosaic_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./result/mosaic.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mmosaic_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2561\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2562\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2563\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2564\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m             \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/result/mosaic.jpg'"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "\n",
        "\n",
        "def crop_to_square(img, size):\n",
        "    \"\"\"\n",
        "    Обрезка изображения до квадратной формы по центру.\n",
        "    \"\"\"\n",
        "    # Определение текущих размеров\n",
        "    width, height = img.size\n",
        "\n",
        "    # Определение размера для обрезки\n",
        "    new_size = min(width, height, size)\n",
        "\n",
        "    # Вычисление координат для обрезки\n",
        "    left = (width - new_size) / 2\n",
        "    top = (height - new_size) / 2\n",
        "    right = (width + new_size) / 2\n",
        "    bottom = (height + new_size) / 2\n",
        "\n",
        "    # Обрезка и возврат изображения\n",
        "    img = img.crop((left, top, right, bottom))\n",
        "    return img.resize((size, size), Image.Resampling.LANCZOS)\n",
        "\n",
        "\n",
        "# Пути к изображениям, которые будут включены в мозаику\n",
        "image_paths = [\"image1.jpg\", \"image2.jpg\", \"image3.jpg\", \"image4.jpg\"]\n",
        "\n",
        "# Открытие изображений и их сохранение в список\n",
        "images = [Image.open(f\"{x}\") for x in image_paths]\n",
        "\n",
        "# Определение минимального размера среди всех изображений\n",
        "min_size = min(min(img.size) for img in images)\n",
        "\n",
        "# Обрезка изображений до квадратов и изменение их размера\n",
        "squared_images = [crop_to_square(img, min_size) for img in images]\n",
        "\n",
        "# Создание нового пустого изображения для мозаики\n",
        "mosaic_size = (min_size * 2, min_size * 2)\n",
        "mosaic_image = Image.new(\"RGB\", mosaic_size, (255, 255, 255))\n",
        "\n",
        "# Размещение изображений в мозаике\n",
        "positions = [(0, 0), (min_size, 0), (0, min_size), (min_size, min_size)]\n",
        "for img, pos in zip(squared_images, positions):\n",
        "    mosaic_image.paste(img, pos)\n",
        "\n",
        "# Сохранение и показ мозаики\n",
        "mosaic_image.save(\"./result/mosaic.jpg\")\n",
        "mosaic_image.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8HJzTvZnJXk"
      },
      "source": [
        "### Построение панорамных изображений\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Nk4OaGW8nJXk"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def create_panorama(image1_path, image2_path, output_path=\"panorama.jpg\"):\n",
        "    # Загружаем изображения\n",
        "    image1 = cv2.imread(image1_path)\n",
        "    image2 = cv2.imread(image2_path)\n",
        "\n",
        "    # Инициализируем ORB детектор\n",
        "    orb = cv2.ORB_create()\n",
        "\n",
        "    # Находим ключевые точки и дескрипторы с помощью ORB\n",
        "    keypoints1, descriptors1 = orb.detectAndCompute(image1, None)\n",
        "    keypoints2, descriptors2 = orb.detectAndCompute(image2, None)\n",
        "\n",
        "    # Создаем объект BFMatcher и совершаем сопоставление дескрипторов\n",
        "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "    matches = bf.match(descriptors1, descriptors2)\n",
        "\n",
        "    # Сортируем сопоставления по расстоянию (лучшие сопоставления первые)\n",
        "    matches = sorted(matches, key=lambda x: x.distance)\n",
        "\n",
        "    # Извлекаем координаты соответствующих ключевых точек для сопоставленных дескрипторов\n",
        "    points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
        "    points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
        "\n",
        "    for i, match in enumerate(matches):\n",
        "        points1[i, :] = keypoints1[match.queryIdx].pt\n",
        "        points2[i, :] = keypoints2[match.trainIdx].pt\n",
        "\n",
        "    # Находим матрицу гомографии\n",
        "    H, _ = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
        "\n",
        "    # Применяем преобразование гомографии к изображению 1\n",
        "    height, width, channels = image2.shape\n",
        "    panorama = cv2.warpPerspective(image1, H, (width * 2, height))\n",
        "\n",
        "    # Копируем изображение 2 в панорамное изображение\n",
        "    panorama[0 : image2.shape[0], 0 : image2.shape[1]] = image2\n",
        "\n",
        "    # Сохраняем панорамное изображение\n",
        "    cv2.imwrite(output_path, panorama)\n",
        "\n",
        "\n",
        "# Пример использования:\n",
        "create_panorama(\"panorama02.jpg\", \"panorama01.jpg\", \"output_panorama.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9xO9E3vnJXk"
      },
      "source": [
        "## Распознавание лиц\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "Y64mlcjZnJXk",
        "outputId": "eb5a0fd4-98d2-4067-a57b-8e563aacb001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (10.4.0)\n",
            "Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566164 sha256=7e00a88293309c29137b6dbf906950966fcc7b4b73e5f8845d35e057714093ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error while calling cudaGetDevice(&the_device_id) in file /tmp/pip-install-don9buxi/dlib_1f308c2e29ca4ef1ad3bf1b73c1cf6b9/dlib/cuda/gpu_data.cpp:204. code: 35, reason: CUDA driver version is insufficient for CUDA runtime version",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-63a54dd687f8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install face_recognition'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"3faces.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"manyfaces.jpg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/face_recognition/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1.2.3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_image_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_face_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_landmarks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/face_recognition/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcnn_face_detection_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detector_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mcnn_face_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detection_model_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_face_detection_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mface_recognition_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_recognition_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error while calling cudaGetDevice(&the_device_id) in file /tmp/pip-install-don9buxi/dlib_1f308c2e29ca4ef1ad3bf1b73c1cf6b9/dlib/cuda/gpu_data.cpp:204. code: 35, reason: CUDA driver version is insufficient for CUDA runtime version"
          ]
        }
      ],
      "source": [
        "!pip install face_recognition\n",
        "import face_recognition\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "face = [\"3faces.jpg\", \"manyfaces.jpg\"]\n",
        "# Загрузка изображения\n",
        "image_path = f\"./data/faces/{face[0]}\"\n",
        "image = face_recognition.load_image_file(image_path)\n",
        "\n",
        "# Нахождение лиц на изображении\n",
        "face_locations = face_recognition.face_locations(image)\n",
        "\n",
        "# Вывод результатов\n",
        "print(f\"Найдено лиц: {len(face_locations)}\")\n",
        "plt.imshow(image)\n",
        "for face_location in face_locations:\n",
        "    top, right, bottom, left = face_location\n",
        "    plt.plot([left, right, right, left, left], [top, top, bottom, bottom, top], \"r-\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "sYP0L_zYnJXl",
        "outputId": "8cf919fd-ba01-4fa4-c9ea-c97530dfadc5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/./data/plibrary/src'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-72b310423560>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Обработка всех изображений в папке\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mprocess_images_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-72b310423560>\u001b[0m in \u001b[0;36mprocess_images_folder\u001b[0;34m(input_folder, output_folder, target_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_output_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_input_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0minput_image_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_input_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/./data/plibrary/src'"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "\n",
        "def resize_image(input_image_path, output_image_path, target_size):\n",
        "    with Image.open(input_image_path) as image:\n",
        "        original_width, original_height = image.size\n",
        "        max_dimension = max(original_width, original_height)\n",
        "        scale = target_size / max_dimension\n",
        "        new_width = int(original_width * scale)\n",
        "        new_height = int(original_height * scale)\n",
        "\n",
        "        resized_image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
        "        resized_image.save(output_image_path)\n",
        "\n",
        "\n",
        "def process_images_folder(input_folder, output_folder, target_size):\n",
        "    # Получение абсолютных путей папок\n",
        "    script_dir = os.getcwd()\n",
        "    abs_input_folder = os.path.join(script_dir, input_folder)\n",
        "    abs_output_folder = os.path.join(script_dir, output_folder)\n",
        "\n",
        "    if not os.path.exists(abs_output_folder):\n",
        "        os.makedirs(abs_output_folder)\n",
        "\n",
        "    for filename in os.listdir(abs_input_folder):\n",
        "        input_image_path = os.path.join(abs_input_folder, filename)\n",
        "        if os.path.isfile(input_image_path):\n",
        "            output_image_path = os.path.join(abs_output_folder, filename)\n",
        "            try:\n",
        "                resize_image(input_image_path, output_image_path, target_size)\n",
        "                print(f\"Image {filename} resized and saved to {output_folder}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing file {filename}: {e}\")\n",
        "\n",
        "\n",
        "# Пути к папкам относительно скрипта\n",
        "input_folder = \"./data/plibrary/src\"\n",
        "output_folder = \"./data/plibrary/resampled\"\n",
        "target_size = 800  # Целевой размер для большей стороны изображения\n",
        "\n",
        "# Обработка всех изображений в папке\n",
        "process_images_folder(input_folder, output_folder, target_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R10zFt8gnJXl"
      },
      "outputs": [],
      "source": [
        "import face_recognition\n",
        "import os\n",
        "from shutil import copy2\n",
        "\n",
        "\n",
        "def filter_images_with_faces(source_folder, destination_folder):\n",
        "    # Создание папки назначения, если она не существует\n",
        "    if not os.path.exists(destination_folder):\n",
        "        os.makedirs(destination_folder)\n",
        "\n",
        "    # Перебор всех файлов в исходной папке\n",
        "    for filename in os.listdir(source_folder):\n",
        "        file_path = os.path.join(source_folder, filename)\n",
        "\n",
        "        # Убедитесь, что это файл и он имеет расширение изображения\n",
        "        if os.path.isfile(file_path) and filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "            try:\n",
        "                # Загрузка изображения и поиск лиц\n",
        "                image = face_recognition.load_image_file(file_path)\n",
        "                face_locations = face_recognition.face_locations(image)\n",
        "\n",
        "                # Если лица обнаружены, копировать файл в папку назначения\n",
        "                if len(face_locations) > 0:\n",
        "                    destination_path = os.path.join(destination_folder, filename)\n",
        "                    copy2(file_path, destination_path)\n",
        "                    print(f\"Image {filename} has faces and was copied.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing file {filename}: {e}\")\n",
        "\n",
        "\n",
        "# Задайте пути к папкам\n",
        "script_dir = os.getcwd()\n",
        "source_folder = os.path.join(script_dir, \"./data/plibrary/resampled\")\n",
        "destination_folder = os.path.join(script_dir, \"./data/plibrary/justfaces\")\n",
        "\n",
        "# Фильтрация изображений\n",
        "filter_images_with_faces(source_folder, destination_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p17UW2SpnJXl"
      },
      "outputs": [],
      "source": [
        "import face_recognition\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "def create_directory_if_not_exists(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "\n",
        "def find_face_encodings(image_path):\n",
        "    image = face_recognition.load_image_file(image_path)\n",
        "    return face_recognition.face_encodings(image)\n",
        "\n",
        "\n",
        "def are_faces_same(face_encoding, known_faces):\n",
        "    # Если нет известных лиц, не сравниваем\n",
        "    if len(known_faces) == 0:\n",
        "        return -1\n",
        "    distances = face_recognition.face_distance(known_faces, face_encoding)\n",
        "    best_match_index = distances.argmin()\n",
        "    if distances[best_match_index] < 0.6:\n",
        "        return best_match_index\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "\n",
        "source_folder = os.path.join(script_dir, \"./data/plibrary/justfaces\")\n",
        "destination_folder = os.path.join(script_dir, \"./data/plibrary/grouped\")\n",
        "create_directory_if_not_exists(destination_folder)\n",
        "\n",
        "known_faces = []\n",
        "face_folders = []\n",
        "\n",
        "# Перебор всех файлов в исходной папке\n",
        "for filename in os.listdir(source_folder):\n",
        "    if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "        image_path = os.path.join(source_folder, filename)\n",
        "        image_encodings = find_face_encodings(image_path)\n",
        "\n",
        "        for encoding in image_encodings:\n",
        "            match_index = are_faces_same(encoding, known_faces)\n",
        "\n",
        "            if match_index != -1:\n",
        "                # Лицо совпадает с известным, копируем в соответствующую папку\n",
        "                shutil.copy2(image_path, face_folders[match_index])\n",
        "            else:\n",
        "                # Новое лицо, создаем для него папку\n",
        "                new_folder_path = os.path.join(destination_folder, f\"person_{len(known_faces)}\")\n",
        "                create_directory_if_not_exists(new_folder_path)\n",
        "                shutil.copy2(image_path, new_folder_path)\n",
        "\n",
        "                # Добавляем лицо и папку в известные\n",
        "                known_faces.append(encoding)\n",
        "                face_folders.append(new_folder_path)\n",
        "\n",
        "print(f\"Фотографии были сгруппированы по {len(known_faces)} лицам.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inqevsncnJXm"
      },
      "source": [
        "## Коллекции для обучения\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-F282jGnJXm"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_lfw_people\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Загрузка набора данных LFW\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
        "\n",
        "# Получение ссылок на изображения и их метки\n",
        "images = lfw_people.images\n",
        "target_names = lfw_people.target_names\n",
        "targets = lfw_people.target\n",
        "\n",
        "# Отображение первых 3 изображений\n",
        "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
        "for i in range(3):\n",
        "    ax[i].imshow(images[i], cmap=\"gray\")\n",
        "    ax[i].set_title(target_names[targets[i]])\n",
        "    ax[i].axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhS4VpGZnJXm"
      },
      "source": [
        "## Квантование многомерных признаков\n",
        "\n",
        "КМП - это процесс преобразования непрерывных или многомерных признаков в дискретные значения, часто используемый для уменьшения количества различных признаков и упрощения алгоритмов машинного обучения, в том числе в контексте классификации изображений и поиска похожих изображений.\n",
        "\n",
        "В контексте классификации изображений и поиска похожих изображений, одним из распространенных подходов является использование векторов признаков, извлеченных из изображений с помощью предварительно обученных моделей глубокого обучения (например, сетей на основе архитектуры CNN). Квантование этих векторов признаков позволяет сократить объем хранимых данных и ускорить процесс сравнения изображений.\n",
        "\n",
        "В качестве примера, давайте рассмотрим использование предварительно обученной модели CNN для извлечения признаков из изображений и их последующее квантование с помощью алгоритма K-средних (K-means). Затем мы можем использовать эти квантованные признаки для поиска похожих изображений.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UnYyJ7CnJXm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Загрузка предварительно обученной модели ResNet50 без верхнего слоя\n",
        "base_model = ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
        "\n",
        "\n",
        "def extract_features(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
        "    preprocessed_img = preprocess_input(expanded_img_array)\n",
        "    features = model.predict(preprocessed_img)\n",
        "    return features.flatten()\n",
        "\n",
        "\n",
        "def get_features_from_folder(folder_path):\n",
        "    features_list = []\n",
        "    images_paths = []\n",
        "    for img_name in os.listdir(folder_path):\n",
        "        if img_name.lower().endswith((\"png\", \"jpg\", \"jpeg\")):\n",
        "            img_path = os.path.join(folder_path, img_name)\n",
        "            features = extract_features(img_path)\n",
        "            features_list.append(features)\n",
        "            images_paths.append(img_path)\n",
        "    return features_list, images_paths\n",
        "\n",
        "\n",
        "# Извлекаем признаки из всех изображений в папке\n",
        "folder_path = os.path.join(script_dir, \"./data/plibrary/justfaces\")\n",
        "features_list, images_paths = get_features_from_folder(folder_path)\n",
        "\n",
        "# Применяем K-средние для квантования признаков\n",
        "num_clusters = 3  # Примерное количество ожидаемых групп\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(features_list)\n",
        "\n",
        "# Находим индекс центроида для каждого изображения\n",
        "labels = kmeans.labels_\n",
        "\n",
        "# Группировка изображений по кластерам\n",
        "clustered_images = {}\n",
        "for i, label in enumerate(labels):\n",
        "    clustered_images.setdefault(label, []).append(images_paths[i])\n",
        "\n",
        "# Вывод результатов группировки\n",
        "\"\"\" for cluster_id, images in clustered_images.items():\n",
        "    print(f\"Cluster {cluster_id}:\")\n",
        "    for img_path in images:\n",
        "        print(f\" - {img_path}\") \"\"\"\n",
        "# Выведем на экран\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def create_thumbnail(image_path, thumbnail_size=(100, 100)):\n",
        "    with Image.open(image_path) as img:\n",
        "        img.thumbnail(thumbnail_size)\n",
        "        return img\n",
        "\n",
        "\n",
        "def display_clustered_images(clustered_images, images_per_row=5):\n",
        "    for cluster_id, images in clustered_images.items():\n",
        "        print(f\"Cluster {cluster_id} contains {len(images)} images.\")\n",
        "        num_rows = int(np.ceil(len(images) / images_per_row))\n",
        "        num_cols = min(images_per_row, len(images))\n",
        "\n",
        "        if len(images) == 1:\n",
        "            fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(5, 5))\n",
        "            axs = np.array([[axs]])  # Обеспечиваем 2D массив для единообразия\n",
        "        else:\n",
        "            fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(15, 3 * num_rows))\n",
        "            axs = np.atleast_2d(axs)  # Убеждаемся, что axs всегда 2D массив\n",
        "\n",
        "        # Преобразуем axs в 1D массив для упрощения итерации\n",
        "        axs_flat = axs.ravel()\n",
        "\n",
        "        for ax, img_path in zip(axs_flat, images):\n",
        "            thumbnail = create_thumbnail(img_path)\n",
        "            ax.imshow(thumbnail)\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "        # Скрываем пустые ячейки\n",
        "        for ax in axs_flat[len(images) :]:\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Отображаем изображения по кластерам\n",
        "display_clustered_images(clustered_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUGu9kDcnJXm"
      },
      "source": [
        "### Извлечение признаков с помощью Пространственной Пирамиды\n",
        "\n",
        "Для классификации изображений с использованием пространственной пирамиды, мы адаптируем предыдущий алгоритм, добавив этап создания пространственной пирамиды изображений перед кластеризацией с помощью K-средних. Это позволит нам учитывать локальные признаки на разных масштабах, что может улучшить точность классификации.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IcvOYC8nJXm"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def extract_pyramid_features(img_path, model, levels=[1, 2, 4]):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "\n",
        "    # Исходные размеры изображения\n",
        "    base_height, base_width = img_array.shape[1:3]\n",
        "\n",
        "    features = []\n",
        "    for level in levels:\n",
        "        for y in range(level):\n",
        "            for x in range(level):\n",
        "                # Вычисление координат области для текущего уровня\n",
        "                width = base_width // level\n",
        "                height = base_height // level\n",
        "                x_start = x * width\n",
        "                y_start = y * height\n",
        "\n",
        "                # Вырезаем часть изображения и извлекаем признаки\n",
        "                img_crop = img_array[:, y_start : y_start + height, x_start : x_start + width, :]\n",
        "                crop_features = model.predict(img_crop)\n",
        "                features.append(crop_features.flatten())\n",
        "\n",
        "    # Объединение признаков со всех уровней\n",
        "    final_features = np.concatenate(features)\n",
        "    return final_features\n",
        "\n",
        "\n",
        "# Загрузка модели\n",
        "model = ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "\n",
        "# Пример извлечения признаков\n",
        "img_path = \"./data/plibrary/justfaces/img_09.jpg\"\n",
        "features = extract_pyramid_features(img_path, model)\n",
        "\n",
        "print(f\"Извлеченные признаки: {features.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5lrIETWnJXn"
      },
      "outputs": [],
      "source": [
        "def extract_pyramid_features(img_path, model, levels=[1, 2, 4]):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "\n",
        "    features = []\n",
        "    for level in levels:\n",
        "        scale = 224 // level\n",
        "        for y in range(level):\n",
        "            for x in range(level):\n",
        "                # Изменение размера и обрезка для создания пирамиды\n",
        "                resized_img = image.smart_resize(img_array, (scale * level, scale * level))\n",
        "                cropped_img = resized_img[:, y * scale : (y + 1) * scale, x * scale : (x + 1) * scale, :]\n",
        "                # Извлечение признаков\n",
        "                feature = model.predict(cropped_img).flatten()\n",
        "                features.append(feature)\n",
        "\n",
        "    # Объединение признаков со всех уровней\n",
        "    final_features = np.concatenate(features)\n",
        "    return final_features\n",
        "\n",
        "\n",
        "# Загрузка предварительно обученной модели\n",
        "model = ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "\n",
        "# Извлечение признаков из всех изображений в папке\n",
        "features_list, images_paths = get_features_from_folder(folder_path)\n",
        "\n",
        "# Квантование признаков\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(features_list)\n",
        "\n",
        "# Находим индекс центроида для каждого изображения\n",
        "labels = kmeans.labels_\n",
        "\n",
        "# Группировка изображений по кластерам\n",
        "clustered_images = {}\n",
        "for i, label in enumerate(labels):\n",
        "    clustered_images.setdefault(label, []).append(images_paths[i])\n",
        "\n",
        "# Отображаем изображения по кластерам\n",
        "display_clustered_images(clustered_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPh5u1GrnJXn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Загрузка предварительно обученной модели ResNet50 без верхнего слоя\n",
        "base_model = ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
        "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
        "\n",
        "\n",
        "def extract_features(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
        "    preprocessed_img = preprocess_input(expanded_img_array)\n",
        "    features = model.predict(preprocessed_img)\n",
        "    return features.flatten()\n",
        "\n",
        "\n",
        "def extract_pyramid_features(img_path, model, levels=[1, 2, 4]):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
        "    preprocessed_img = preprocess_input(expanded_img_array)\n",
        "\n",
        "    features = []\n",
        "    for level in levels:\n",
        "        level_features = []\n",
        "        step_size = 224 // level\n",
        "        for y in range(level):\n",
        "            for x in range(level):\n",
        "                crop = preprocessed_img[:, y * step_size : (y + 1) * step_size, x * step_size : (x + 1) * step_size, :]\n",
        "                crop_features = model.predict(crop).flatten()\n",
        "                level_features.append(crop_features)\n",
        "        features.extend(level_features)\n",
        "    return np.concatenate(features)\n",
        "\n",
        "\n",
        "def get_features_from_folder(folder_path):\n",
        "    features_list = []\n",
        "    images_paths = []\n",
        "    for img_name in os.listdir(folder_path):\n",
        "        if img_name.lower().endswith((\"png\", \"jpg\", \"jpeg\")):\n",
        "            img_path = os.path.join(folder_path, img_name)\n",
        "            features = extract_pyramid_features(img_path, model)\n",
        "            features_list.append(features)\n",
        "            images_paths.append(img_path)\n",
        "    return features_list, images_paths\n",
        "\n",
        "\n",
        "# Извлекаем признаки из всех изображений в папке\n",
        "script_dir = os.getcwd()\n",
        "folder_path = os.path.join(script_dir, \"./data/plibrary/justfaces\")\n",
        "features_list, images_paths = get_features_from_folder(folder_path)\n",
        "\n",
        "# Применяем K-средние для квантования признаков\n",
        "num_clusters = 4  # Примерное количество ожидаемых групп\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(features_list)\n",
        "\n",
        "# Находим индекс центроида для каждого изображения\n",
        "labels = kmeans.labels_\n",
        "\n",
        "# Группировка изображений по кластерам\n",
        "clustered_images = {}\n",
        "for i, label in enumerate(labels):\n",
        "    clustered_images.setdefault(label, []).append(images_paths[i])\n",
        "\n",
        "\n",
        "def display_clustered_images(clustered_images, images_per_row=5):\n",
        "    for cluster_id, images in clustered_images.items():\n",
        "        print(f\"Cluster {cluster_id} contains {len(images)} images.\")\n",
        "        num_rows = int(np.ceil(len(images) / images_per_row))\n",
        "        num_cols = min(images_per_row, len(images))\n",
        "\n",
        "        if len(images) == 1:\n",
        "            fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(5, 5))\n",
        "            axs = np.array([[axs]])  # Обеспечиваем 2D массив для единообразия\n",
        "        else:\n",
        "            fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(15, 3 * num_rows))\n",
        "            axs = np.atleast_2d(axs)  # Убеждаемся, что axs всегда 2D массив\n",
        "\n",
        "        # Преобразуем axs в 1D массив для упрощения итерации\n",
        "        axs_flat = axs.ravel()\n",
        "\n",
        "        for ax, img_path in zip(axs_flat, images):\n",
        "            thumbnail = create_thumbnail(img_path)\n",
        "            ax.imshow(thumbnail)\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "        # Скрываем пустые ячейки\n",
        "        for ax in axs_flat[len(images) :]:\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Вывод результатов группировки\n",
        "display_clustered_images(clustered_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to7QY9YDnJXn"
      },
      "source": [
        "# Работа с векторной БД\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9MVlbQKnJXn"
      },
      "outputs": [],
      "source": [
        "from annoy import AnnoyIndex\n",
        "import numpy as np\n",
        "\n",
        "# Предполагаем, что extract_pyramid_features и model уже определены\n",
        "feature_dim = 43008  # Задайте размерность вашего вектора признаков\n",
        "index = AnnoyIndex(feature_dim, \"euclidean\")  # Используем Евклидово расстояние\n",
        "\n",
        "features_list, images_paths = get_features_from_folder(folder_path)\n",
        "for i, features in enumerate(features_list):\n",
        "    index.add_item(i, features)\n",
        "\n",
        "index.build(10)  # 10 деревьев\n",
        "index.save(\"./data/image_features.ann\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh_5keepnJXo"
      },
      "outputs": [],
      "source": [
        "# Загрузка индекса\n",
        "index = AnnoyIndex(feature_dim, \"euclidean\")\n",
        "index.load(\"./data/image_features.ann\")\n",
        "\n",
        "# Извлечение признаков для целевого изображения\n",
        "target_features = extract_pyramid_features(\"./data/plibrary/justfaces/img_06.jpg\", model)\n",
        "\n",
        "# Поиск ближайших соседей\n",
        "nearest_ids = index.get_nns_by_vector(target_features, 5)  # Ищем 5 ближайших соседей\n",
        "\n",
        "# Получение путей к ближайшим изображениям\n",
        "nearest_image_paths = [images_paths[i] for i in nearest_ids]\n",
        "\n",
        "print(nearest_image_paths)\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def display_images(image_paths):\n",
        "    fig, axes = plt.subplots(1, len(image_paths), figsize=(20, 10))\n",
        "    for ax, img_path in zip(axes, image_paths):\n",
        "        img = Image.open(img_path)\n",
        "        ax.imshow(img)\n",
        "        ax.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "display_images(nearest_image_paths)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc_Wm6g8Us8b",
        "outputId": "621f928d-b9cc-4bd2-e1cd-22d7e84135ed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m 'Часть модуля 2'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXyQFNWqUy1G",
        "outputId": "c4d17908-c666-4c54-94e4-8156e7d11088"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBcBpCJGU5Rl",
        "outputId": "795cd9cd-f591-4e52-cc56-07f8fa812239"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfCUg2_fWJJg",
        "outputId": "0181eb70-e868-433f-c837-5578ba578ae2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd"
      ],
      "metadata": {
        "id": "AeDouVMjXH36"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PfykaQPXJ5q",
        "outputId": "c181faac-cb9e-45f9-c954-66b8b2f7f927"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n",
            "           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n",
            "           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n",
            "           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n",
            "           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n",
            "           <command> [<args>]\n",
            "\n",
            "These are common Git commands used in various situations:\n",
            "\n",
            "start a working area (see also: git help tutorial)\n",
            "   clone     Clone a repository into a new directory\n",
            "   init      Create an empty Git repository or reinitialize an existing one\n",
            "\n",
            "work on the current change (see also: git help everyday)\n",
            "   add       Add file contents to the index\n",
            "   mv        Move or rename a file, a directory, or a symlink\n",
            "   restore   Restore working tree files\n",
            "   rm        Remove files from the working tree and from the index\n",
            "\n",
            "examine the history and state (see also: git help revisions)\n",
            "   bisect    Use binary search to find the commit that introduced a bug\n",
            "   diff      Show changes between commits, commit and working tree, etc\n",
            "   grep      Print lines matching a pattern\n",
            "   log       Show commit logs\n",
            "   show      Show various types of objects\n",
            "   status    Show the working tree status\n",
            "\n",
            "grow, mark and tweak your common history\n",
            "   branch    List, create, or delete branches\n",
            "   commit    Record changes to the repository\n",
            "   merge     Join two or more development histories together\n",
            "   rebase    Reapply commits on top of another base tip\n",
            "   reset     Reset current HEAD to the specified state\n",
            "   switch    Switch branches\n",
            "   tag       Create, list, delete or verify a tag object signed with GPG\n",
            "\n",
            "collaborate (see also: git help workflows)\n",
            "   fetch     Download objects and refs from another repository\n",
            "   pull      Fetch from and integrate with another repository or a local branch\n",
            "   push      Update remote refs along with associated objects\n",
            "\n",
            "'git help -a' and 'git help -g' list available subcommands and some\n",
            "concept guides. See 'git help <command>' or 'git help <concept>'\n",
            "to read about a specific subcommand or concept.\n",
            "See 'git help git' for an overview of the system.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd image_processing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teX-GwYWYAKd",
        "outputId": "3d5c3e71-a693-4bc9-ed42-98bf0ebc972c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'image_processing'\n",
            "/content/image_processing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add"
      ],
      "metadata": {
        "id": "uCgYm9JBYHDZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}